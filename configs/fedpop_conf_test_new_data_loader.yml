data_params:
  dataset_name: fmnist
  root_path: data/MNIST
  generate_dataloaders: True
  train_batch_size: 50  # Augmentation pour une meilleure stabilité
  test_batch_size: 50
  regression: False
  max_dataset_size_per_user: 200  # Taille de dataset augmentée
  n_clients_with_min_datasets: 0
  specific_dataset_params:
    n_clients: 5  # Augmenté pour améliorer la diversité
    num_classes: 10
    classes_per_user: 5  # Augmentation des classes par utilisateur

eval_params:
  metrics:
    - accuracy

model_params:
  backbone_model_name: IdenticalBackbone
  backbone_model_params:
    backbone_embedding_size: 10
  composition_model_regime: composition
  personal_model_name: MLP_MNIST_personal
  personal_model_params:
    input_size: 64
    n_classes: 10
  prior_model_name: GaussianPriorModel
  prior_model_params:
    fix_mu: true
    fix_scale: true
    in_features: 650  # À ajuster si nécessaire selon les données réelles
    n_modes: null
    scale_init: 0.54
    scale_value: 0.54
  shared_model_name: MLP_MNIST
  shared_model_params:
    shared_embedding_size: 64
  shared_prior_model: true

optimization:
  backbone_optimizer: Adam
  backbone_optimizer_params: { }
  backbone_scheduler: CyclicLR
  backbone_scheduler_params:
    base_lr: 0.001
    cycle_momentum: false
    gamma: 0.99
    max_lr: 0.003
    mode: exp_range
    step_size_up: 10  # Rétabli pour plus de stabilité
  personal_optimizer: Adam
  personal_optimizer_params:
    lr: 0.1
  personal_scheduler: MultiStepLR
  personal_scheduler_params:
    gamma: 0.5
    milestones:
      - 10  # Ajusté pour des tests plus longs
      - 20
  prior_model_optimizer: Adam
  prior_model_optimizer_params:
    lr: 0.1
  prior_model_scheduler: MultiStepLR
  prior_model_scheduler_params:
    gamma: 0.5
    milestones:
      - 10
      - 20
  shared_optimizer: Adam
  shared_optimizer_params: { }
  shared_scheduler: CyclicLR
  shared_scheduler_params:
    base_lr: 0.001
    cycle_momentum: false
    gamma: 0.1
    max_lr: 0.003
    mode: exp_range
    step_size_up: 10  # Augmenté pour refléter les changements des autres itérations

train_params:
  algorithm: FedPop
  clients_sample_size: 3  # Augmenté pour mieux refléter les données disponibles
  device: cuda
  exp_folder: ./experiment_logs_mnist/
  inner_burn_in: 3  # Ajusté pour donner plus de temps à l'entraînement
  inner_iters: 5
  loss_fn_name: cross_entropy
  outer_iters: 10  # Réduction légère pour des tests plus courts
  prior: gaussian
  seeds:
    - 41
  use_sgld: false
  verbose: true  # Activer le mode détaillé pour diagnostiquer les problèmes
  verbose_freq: 1
